{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1582lL7E-eJ"
      },
      "source": [
        "## check for GPU's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqe1kXPcXj1U"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y60e3m2FRZY"
      },
      "source": [
        "## Requirements\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU14wTLeZBh3"
      },
      "source": [
        " We install of pytorch-ignite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWN63EToZA-G"
      },
      "outputs": [],
      "source": [
        " !pip install --pre pytorch-ignite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8M6GlpmQ5jZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import ignite\n",
        "torch.__version__, ignite.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3LCqCufFRZ6"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "seed = 17\n",
        "random.seed(seed)\n",
        "_ = torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset"
      ],
      "metadata": {
        "id": "K3nM9OK6aCQT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOPsiJWkJGRs"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOr3nd4qFRaB"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "class FilesDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, path, extension=\"*.png\"):\n",
        "        self.path = Path(path)\n",
        "        assert self.path.exists(), \"Path '{}' is not found\".format(path)\n",
        "        self.images = list(self.path.rglob(extension))\n",
        "        assert len(self.images) > 0, \"No images with extension {} found at '{}'\".format(extension, path)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        return Image.open(self.images[i]).convert('RGB')\n",
        "\n",
        "\n",
        "class FilesDataset2(Dataset):\n",
        "    \n",
        "    def __init__(self, path, extension=\"*.jpg\"):\n",
        "        self.path = Path(path)\n",
        "        assert self.path.exists(), \"Path '{}' is not found\".format(path)\n",
        "        self.images = list(self.path.rglob(extension))\n",
        "        assert len(self.images) > 0, \"No images with extension {} found at '{}'\".format(extension, path)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        return Image.open(self.images[i]).convert('RGB')        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byG73rBHFRaG"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "root = Path(\"/content/drive/MyDrive/ML_Datasets/Task_4/testing/dataset/\")\n",
        "test_path=Path('/content/drive/MyDrive/ML_Datasets/Task_4/pizza_test')\n",
        "\n",
        "assert root.exists(), \"Path '{}' is not found\".format(root)\n",
        "#train_A = FilesDataset(root / \"synthetic test\")\n",
        "#train_B = FilesDataset2(root / \"real test\")\n",
        "\n",
        "train_A = FilesDataset(root)\n",
        "train_B = FilesDataset(root)\n",
        "test_A = FilesDataset(root)\n",
        "test_B = FilesDataset(root)\n",
        "#test_A = FilesDataset(root / \"synthetic test\") \n",
        "#test_B = FilesDataset2(root / \"real test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv1oXmSJFRaK"
      },
      "source": [
        "Some details on the datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZ4rY5S9FRaL"
      },
      "outputs": [],
      "source": [
        "print(\"Dataset sizes: \\ntrain A: {} | B: {}\\ntest A: {} | B: {}\\n\\t\".format(len(train_A), len(train_B), len(test_A), len(test_B)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4lyZ6GSFRaR"
      },
      "outputs": [],
      "source": [
        "print(\"Train random image sizes (A): {}, {}, {}, {}\".format(train_A[0].size, train_A[1].size, train_A[10].size, train_A[-1].size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-61gbfVFRaX"
      },
      "outputs": [],
      "source": [
        "print(\"Train random image sizes (B): {}, {}, {}, {}\".format(train_B[0].size, train_B[1].size, train_B[10].size, train_B[-1].size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAxkND8jFRac"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pylab as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xx7cAEI0FRah"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(121)\n",
        "plt.title(\"Train dataset 'Real Pizza'\")\n",
        "plt.imshow(train_A[0])\n",
        "plt.subplot(122)\n",
        "plt.title(\"Train dataset 'Synthetic Pizza'\")\n",
        "plt.imshow(train_B[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_v_FuvZFRao"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(121)\n",
        "plt.title(\"Test dataset 'Real Pizza'\")\n",
        "plt.imshow(test_A[0])\n",
        "plt.subplot(122)\n",
        "plt.title(\"Test dataset 'Synthetic Pizza'\")\n",
        "plt.imshow(test_B[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc6ZuUWwFRas"
      },
      "source": [
        "Here we create a dataset composed of random image pairs of datasets A and B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B699THXXFRat"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "\n",
        "class Image2ImageDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, ds_a, ds_b):\n",
        "        self.dataset_a = ds_a\n",
        "        self.dataset_b = ds_b\n",
        "    \n",
        "    def __len__(self):\n",
        "        return max(len(self.dataset_a), len(self.dataset_b))\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        dp_a = self.dataset_a[i % len(self.dataset_a)]\n",
        "        j = random.randint(0, len(self.dataset_b) - 1)\n",
        "        dp_b = self.dataset_b[j]\n",
        "        return {\n",
        "            'A': dp_a,\n",
        "            'B': dp_b\n",
        "        }\n",
        "\n",
        "\n",
        "class TransformedDataset(Dataset):\n",
        "        \n",
        "    def __init__(self, ds, transform):\n",
        "        self.dataset = ds\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        return {k: self.transform(v) for k, v in self.dataset[i].items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF6OQwxoFRax"
      },
      "outputs": [],
      "source": [
        "train_ab_ds = Image2ImageDataset(train_A, train_B)\n",
        "test_ab_ds = Image2ImageDataset(test_A, test_B)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ab_ds[0]"
      ],
      "metadata": {
        "id": "sz7qHguApzZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIcsATwrFRa1"
      },
      "outputs": [],
      "source": [
        "dp = train_ab_ds[20]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(121)\n",
        "plt.title(\"Train dataset 'Pizza'\")\n",
        "plt.imshow(dp['A'])\n",
        "plt.subplot(122)\n",
        "plt.title(\"Train dataset 'Synthetic'\")\n",
        "plt.imshow(dp['B'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3zfGZoOFRa6"
      },
      "outputs": [],
      "source": [
        "dp = test_ab_ds[20]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(121)\n",
        "plt.title(\"Test dataset 'Real Pizza'\")\n",
        "plt.imshow(dp['A'])\n",
        "plt.subplot(122)\n",
        "plt.title(\"Test dataset 'Synthetic Pizza'\")\n",
        "plt.imshow(dp['B'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2Hda4tjFRa-"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import Compose, ColorJitter, RandomHorizontalFlip, ToTensor, Normalize, RandomCrop,Resize\n",
        "\n",
        "# here we are resizing to scale images which are not of size 256*256 to accomodate them \n",
        "train_transform = Compose([\n",
        "    Resize(256),                 \n",
        "    RandomCrop(256),\n",
        "    RandomHorizontalFlip(),\n",
        "    ColorJitter(),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "])\n",
        "transformed_train_ab_ds = TransformedDataset(train_ab_ds, transform=train_transform)\n",
        "\n",
        "\n",
        "batch_size = 1\n",
        "train_ab_loader = DataLoader(transformed_train_ab_ds, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True, num_workers=1)\n",
        "\n",
        "\n",
        "test_transform = Compose([\n",
        "    Resize(256),\n",
        "    RandomCrop(256),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "])\n",
        "transformed_test_ab_ds = TransformedDataset(test_ab_ds, transform=test_transform)\n",
        "batch_size = 1\n",
        "test_ab_loader = DataLoader(transformed_test_ab_ds, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=True, num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtfXU9uaFRbB"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "# Plot some training images\n",
        "real_batch = next(iter(train_ab_loader))\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images from A\")\n",
        "plt.imshow( \n",
        "    vutils.make_grid(real_batch['A'][:64], padding=2, normalize=True).cpu().numpy().transpose((1, 2, 0))\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images from B\")\n",
        "plt.imshow(\n",
        "    vutils.make_grid(real_batch['B'][:64], padding=2, normalize=True).cpu().numpy().transpose((1, 2, 0))\n",
        ")\n",
        "real_batch = None\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlZ39Id-FRbF"
      },
      "source": [
        "# Generator and Activations  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "26xcn8TYXGpf"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard\n",
        "import tensorflow as tf\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MC8VUVeYsvph"
      },
      "outputs": [],
      "source": [
        "def normalize(x):\n",
        "    vmin = x.min()\n",
        "    vmax = x.max()\n",
        "    x.clamp_(min=vmin, max=vmax)\n",
        "    x.add_(-vmin).div_(vmax - vmin + 1e-5)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA9iytfu9kLq"
      },
      "outputs": [],
      "source": [
        "def plot_graphs(c,plot_title, save_file,file_writer):\n",
        "  plt.figure(figsize=(20,5))\n",
        "  plt.title(plot_title)\n",
        "  plt.imshow(c)\n",
        "  with file_writer.as_default():\n",
        "      tf.summary.image(plot_title, np.reshape(c,(1,c.shape[0],c.shape[1],1)), step=0)\n",
        "  plt.savefig(save_file)\n",
        "  plt.show()\n",
        "  plt.clf()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ri6_NvWfFRbG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "\n",
        "def get_conv_inorm_relu(in_planes, out_planes, kernel_size, stride, reflection_pad=True, with_relu=True):\n",
        "    layers = []\n",
        "    padding = (kernel_size - 1) // 2\n",
        "    if reflection_pad:\n",
        "        layers.append(nn.ReflectionPad2d(padding=padding))\n",
        "        padding = 0\n",
        "    layers += [\n",
        "        nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "        nn.InstanceNorm2d(out_planes, affine=False, track_running_stats=False),\n",
        "    ]\n",
        "    if with_relu:\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def get_conv_transposed_inorm_relu(in_planes, out_planes, kernel_size, stride):\n",
        "    return nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=1, output_padding=1),\n",
        "        nn.InstanceNorm2d(out_planes, affine=False, track_running_stats=False),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_planes):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = get_conv_inorm_relu(in_planes, in_planes, kernel_size=3, stride=1)\n",
        "        self.conv2 = get_conv_inorm_relu(in_planes, in_planes, kernel_size=3, stride=1, with_relu=False)        \n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)        \n",
        "        return x + residual\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        \n",
        "        self.c7s1_64 = get_conv_inorm_relu(3, 64, kernel_size=7, stride=1)\n",
        "        self.d128 = get_conv_inorm_relu(64, 128, kernel_size=3, stride=2, reflection_pad=False)\n",
        "        self.d256 = get_conv_inorm_relu(128, 256, kernel_size=3, stride=2, reflection_pad=False)\n",
        "\n",
        "        self.resnet9 = nn.Sequential(*[ResidualBlock(256) for i in range(9)])\n",
        "\n",
        "        self.u128 = get_conv_transposed_inorm_relu(256, 128, kernel_size=3, stride=2)\n",
        "        self.u64 = get_conv_transposed_inorm_relu(128, 64, kernel_size=3, stride=2)\n",
        "        self.c7s1_3 = get_conv_inorm_relu(64, 3, kernel_size=7, stride=1, with_relu=False)\n",
        "        # Replace instance norm by tanh activation\n",
        "        self.c7s1_3[-1] = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoding\n",
        "        # \n",
        "        x = self.c7s1_64(x)\n",
        "        x = self.d128(x)\n",
        "        x = self.d256(x)\n",
        "        # 9 residual blocks\n",
        "        x = self.resnet9(x)\n",
        "        # Decoding\n",
        "        x = self.u128(x)\n",
        "        \n",
        "        x = self.u64(x)\n",
        "      \n",
        "        y = self.c7s1_3(x)\n",
        "        \n",
        "        return y\n",
        "\n",
        "    \n",
        "    def normalize(x):\n",
        "      vmin = x.min()\n",
        "      vmax = x.max()\n",
        "      x.clamp_(min=vmin, max=vmax)\n",
        "      x.add_(-vmin).div_(vmax - vmin + 1e-5)\n",
        "      return x\n",
        "\n",
        "    def showActivations(self,x,epoch,image_number):\n",
        "\n",
        "        save_files ='/content/drive/MyDrive/ML_Datasets/Task_4/Inference/mdf/new_activations'\n",
        "        log_path='/content/drive/MyDrive/ML_Datasets/Task_4/Inference/mdf/logs'+'/epoch_'+str(epoch)\n",
        "        logdir = log_path\n",
        "        file_writer = tf.summary.create_file_writer(logdir)\n",
        "        path=str(save_files)+'/epoch_'+str(epoch)\n",
        "        if not(os.path.isdir(path)):\n",
        "          os.mkdir(path)\n",
        "        print('Epoch ',epoch)\n",
        "        \n",
        "        #Input Image\n",
        "        plt.figure(figsize=(20,5))\n",
        "        plt.title(f\"Input Image Epoch: {epoch}\")\n",
        "        plt.imshow(torch.Tensor.cpu(x[0][0]))\n",
        "        plt.savefig(f'{save_files}/epoch_{epoch}/Input_Image.png')\n",
        "\n",
        "        plt.show();\n",
        "        plt.clf()\n",
        "\n",
        "        #c7s1_64\n",
        "        out = self.c7s1_64(x)\n",
        "        outer=(torch.Tensor.cpu(out).detach())\n",
        "        b=np.array([]).reshape(0,outer.shape[2])\n",
        "        c=np.array([]).reshape(4*outer.shape[2],0)\n",
        "         \n",
        "        # Plotting for layer 1\n",
        "        i=0\n",
        "        j=0\n",
        "        while(i<64):\n",
        "            \n",
        "            img=outer[0][i]\n",
        "            img=normalize(img)\n",
        "            b=np.concatenate((img,b),axis=0)\n",
        "            j+=1\n",
        "            if(j==4):\n",
        "                c=np.concatenate((c,b),axis=1)\n",
        "                b=np.array([]).reshape(0,outer.shape[2])\n",
        "                j=0\n",
        "                \n",
        "            i+=1\n",
        "        if(image_number==0):\n",
        "          plot_graphs(c, f\"c7s1_64 Epoch: {epoch}\", f'{save_files}/epoch_{epoch}/c7s1_64_epoch_{epoch}.png',file_writer)\n",
        "        \n",
        "\n",
        "        #d128\n",
        "        out = self.d128(out)\n",
        "        outer=(torch.Tensor.cpu(out).detach())\n",
        "        b=np.array([]).reshape(0,outer.shape[2])\n",
        "        c=np.array([]).reshape(8*outer.shape[2],0)\n",
        "        \n",
        "        # Plotting for layer2\n",
        "        i=0\n",
        "        j=0\n",
        "        while(i<128):\n",
        "            img=outer[0][i]\n",
        "            img=normalize(img)\n",
        "            b=np.concatenate((img,b),axis=0)\n",
        "            j+=1\n",
        "            if(j==8):\n",
        "                c=np.concatenate((c,b),axis=1)\n",
        "                b=np.array([]).reshape(0,outer.shape[2])\n",
        "                j=0\n",
        "                \n",
        "            i+=1\n",
        "\n",
        "\n",
        "        if(image_number==0):\n",
        "          plot_graphs(c, f\"d128 Epoch: {epoch}\", f'{save_files}/epoch_{epoch}/d128_epoch_{epoch}.png',file_writer)\n",
        "        \n",
        "\n",
        "        #d256\n",
        "        out = self.d256(out)\n",
        "        outer=(torch.Tensor.cpu(out).detach())\n",
        "        #print('d256', outer.shape)\n",
        "        b=np.array([]).reshape(0,outer.shape[2])\n",
        "        c=np.array([]).reshape(8*outer.shape[2],0)\n",
        "        \n",
        "        # Plotting for layer3\n",
        "        j=0\n",
        "        i=0\n",
        "        while(i<256):\n",
        "            img=outer[0][i]\n",
        "            img=normalize(img)\n",
        "            b=np.concatenate((img,b),axis=0)\n",
        "            j+=1\n",
        "            if(j==8):\n",
        "                c=np.concatenate((c,b),axis=1)\n",
        "                b=np.array([]).reshape(0,outer.shape[2])\n",
        "                j=0\n",
        "                \n",
        "            i+=1\n",
        "        \n",
        "        if(image_number==0):\n",
        "          plot_graphs(c, f\"d256 Epoch: {epoch}\", f'{save_files}/epoch_{epoch}/d256_epoch_{epoch}.png',file_writer)\n",
        "        \n",
        "\n",
        "        #resnet\n",
        "        out = self.resnet9(out)\n",
        "        outer=(torch.Tensor.cpu(out).detach())\n",
        "        #print('resnet', outer.shape)\n",
        "      \n",
        "        # Plotting for resnet\n",
        "        j=0\n",
        "        i=0\n",
        "        \n",
        "        b=np.array([]).reshape(0,outer.shape[2])\n",
        "        c=np.array([]).reshape(8*outer.shape[2],0)\n",
        "          \n",
        "        while(i<256):\n",
        "            img=outer[0][i]\n",
        "            img=normalize(img)\n",
        "            b=np.concatenate((img,b),axis=0)\n",
        "            j+=1\n",
        "            if(j==8):\n",
        "                c=np.concatenate((c,b),axis=1)\n",
        "                b=np.array([]).reshape(0,outer.shape[2])\n",
        "                j=0\n",
        "                \n",
        "            i+=1\n",
        "            \n",
        "        if(image_number==0):\n",
        "          plot_graphs(c, f\"resnet Epoch: {epoch}\", f'{save_files}/epoch_{epoch}/resnet_epoch_{epoch}.png',file_writer)\n",
        "        \n",
        "        return c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E98bnPkSG6Zr"
      },
      "source": [
        "#### generator check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfOTRPt4FRbL"
      },
      "outputs": [],
      "source": [
        "x = torch.rand(4, 3, 256, 256)\n",
        "g = Generator()\n",
        "#y = g(x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nC8ThgEXgY6f"
      },
      "outputs": [],
      "source": [
        "c=g.showActivations(x,200000,0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discriminator"
      ],
      "metadata": {
        "id": "OLRFtIR8akfB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdb5-RAYFRbR"
      },
      "outputs": [],
      "source": [
        "def get_conv_inorm_lrelu(in_planes, out_planes, stride=2, negative_slope=0.2):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_planes, out_planes, kernel_size=4, stride=stride, padding=1),\n",
        "        nn.InstanceNorm2d(out_planes, affine=False, track_running_stats=False),\n",
        "        nn.LeakyReLU(negative_slope=negative_slope, inplace=True)\n",
        "    )\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.c64 = nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1)\n",
        "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.c128 = get_conv_inorm_lrelu(64, 128)\n",
        "        self.c256 = get_conv_inorm_lrelu(128, 256)\n",
        "        self.c512 = get_conv_inorm_lrelu(256, 512, stride=1)\n",
        "        self.last_conv = nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c64(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.c128(x)\n",
        "        x = self.c256(x)\n",
        "        x = self.c512(x)\n",
        "        y = self.last_conv(x)\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu2K1U7JFRbU"
      },
      "source": [
        "### Sanity check the Discriminator network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "On4vpLc_FRbV"
      },
      "outputs": [],
      "source": [
        "x = torch.rand(4, 3, 256, 256)\n",
        "d = Discriminator()\n",
        "y = d(x)\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orcYUiDfFRbZ"
      },
      "source": [
        "#Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vId72FGFRba"
      },
      "outputs": [],
      "source": [
        "def init_weights(module):\n",
        "    assert isinstance(module, nn.Module)\n",
        "    if hasattr(module, \"weight\") and module.weight is not None:\n",
        "        torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "    if hasattr(module, \"bias\") and module.bias is not None:\n",
        "        torch.nn.init.constant_(module.bias, 0.0)\n",
        "    for c in module.children():\n",
        "        init_weights(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMoUXZ5yFRbd"
      },
      "outputs": [],
      "source": [
        "g = None; d = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozU5CQ9JFRbh"
      },
      "outputs": [],
      "source": [
        "assert torch.backends.cudnn.enabled\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zZ5ZuXGFRbl"
      },
      "outputs": [],
      "source": [
        "# device = \"cuda\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "generator_A2B = Generator().to(device)\n",
        "init_weights(generator_A2B)\n",
        "\n",
        "discriminator_B = Discriminator().to(device)\n",
        "init_weights(discriminator_B)\n",
        "\n",
        "generator_B2A = Generator().to(device)\n",
        "init_weights(generator_B2A)\n",
        "discriminator_A = Discriminator().to(device)\n",
        "init_weights(discriminator_A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f90Ew1kaFRbo"
      },
      "source": [
        "## Train the networks with a learning rate of `0.0002`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbgTEAMCFRbo"
      },
      "outputs": [],
      "source": [
        "from itertools import chain\n",
        "import torch.optim as optim\n",
        "\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "\n",
        "optimizer_G = optim.Adam(chain(generator_A2B.parameters(), generator_B2A.parameters()), lr=lr, betas=(beta1, 0.999))\n",
        "optimizer_D = optim.Adam(chain(discriminator_A.parameters(), discriminator_B.parameters()), lr=lr, betas=(beta1, 0.999))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CbI9ngDFRcx"
      },
      "source": [
        "# Inference with trained generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgf1Ve8Iww_W"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "d = \"/content/drive/MyDrive/ML_Datasets/Task_4/Inference/mse/models\"\n",
        "epochs=[]\n",
        "for path in os.listdir(d):\n",
        "  epochs.append(int(path[path.rindex('_')+1:path.index('.')]))\n",
        "epochs.sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4XkCTxIRq_6"
      },
      "outputs": [],
      "source": [
        "\n",
        "for epoch in epochs:\n",
        "  total_c=np.array([]).reshape(0, 512*2048)\n",
        "  total_image=np.array([]).reshape(0, 256*256*3)\n",
        "  file='epoch__checkpoint_'+str(epoch)+'.pt'\n",
        "  full_path = os.path.join(d, file)\n",
        "  counter = int(epoch/2664*2)\n",
        "  #Load Model\n",
        "  checkpoint_state_dict = torch.load(full_path, map_location = torch.device('cuda:0'))\n",
        "  generator_A2B.load_state_dict(checkpoint_state_dict[\"generator_A2B\"])\n",
        "    \n",
        "  for i in range(100):\n",
        "    img = test_ab_ds[i]['A']\n",
        "    x = test_transform(img)\n",
        "    total_image=np.concatenate((total_image,np.reshape(torch.Tensor.cpu(x),(1,3*256*256))),axis=0) \n",
        "    \n",
        "    x = x.unsqueeze(0).to(device)\n",
        "    \n",
        "    # genrate the fake image \n",
        "    with torch.no_grad():\n",
        "      g = generator_A2B\n",
        "      y_pred = g(x)\n",
        "      c=g.showActivations(x,counter,i)\n",
        "      total_c=np.concatenate((total_c,np.reshape(c,(1,2048*512))), axis=0)\n",
        "\n",
        "\n",
        "    \n",
        "    # nomralize image \n",
        "    img_pred = (255 * normalize(y_pred[0, ...])).cpu().numpy().transpose((1, 2, 0)).astype('uint8')\n",
        "\n",
        "    \n",
        "    plt.figure(figsize=(20, 5))\n",
        "    plt.title(f\"Generated Image epoch{counter}\")\n",
        "    plt.imshow(img_pred)\n",
        "    plt.savefig(f'{save_files}/epoch_{counter}/Ouput_epoch_{counter}.png')\n",
        "    plt.show()\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ucXZAsrxxCp"
      },
      "source": [
        "# t-SNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uM5xBjfc3vjl"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "from sklearn.manifold import TSNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQHCplcPyOrg"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKqdPf0SyW55"
      },
      "outputs": [],
      "source": [
        "# Enter code here\n",
        "import matplotlib.pyplot as plt\n",
        "def tsne_results(features, new_features, perplexity=10, n_components=2, n_iter=100, n_classes=10, color_palette = \"hls\"):\n",
        "    # Enter code here\n",
        "    # tSNE applied to features with target.\n",
        "    tsne_input = TSNE(n_components = n_components, perplexity = perplexity, n_iter = n_iter).fit_transform(features)\n",
        "    tsne_latent= TSNE(n_components = n_components, perplexity = perplexity, n_iter = n_iter).fit_transform(new_features)\n",
        "\n",
        "\n",
        "\n",
        "    plt.scatter(tsne_input[:,0], tsne_input[:,1], label='Input')\n",
        "    plt.scatter(tsne_latent[:,0], tsne_latent[:,1], label='Latent Space')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    return tsne_em\n",
        "res = tsne_results(total_image,total_c, perplexity=300, n_components=2, n_iter=250, n_classes=10, color_palette = \"hls\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3fKpOKrh7gI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "latent_space.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}